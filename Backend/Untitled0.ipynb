{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyOVoBlEVneK86A0/EhxKuYN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShagufthaZK/IR_project/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "roosPqyS-t3m"
      },
      "outputs": [],
      "source": [
        "!pip install pyngrok\n",
        "!pip install Flask-WTF\n",
        "!pip install Flask-Bootstrap4"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tfkit==0.7.21 nlp2go==0.4.12\n",
        "!pip install git+https://github.com/roemmele/answerquest.git\n",
        "!pip install torch==1.10.0+cu111 -f https://download.pytorch.org/whl/cu111/torch_stable.html\n",
        "!pip install pywsd\n",
        "!pip install -U wn==0.0.22"
      ],
      "metadata": {
        "id": "3Sr8VVyCs1av"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/roemmele/answerquest.git\n",
        "!bash /content/answerquest/download_models.sh"
      ],
      "metadata": {
        "id": "5K9nxHj-tqeJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "y-KQjrMzWR-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r /content/doc_qa_model /content/gdrive/MyDrive/IR_code\n",
        "# !cp -r /content/qg_augmented_model /content/gdrive/MyDrive/IR_code"
      ],
      "metadata": {
        "id": "Tan2e3k0t8K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget https://github.com/voidful/BDG/releases/download/v1.0/BDG_ANPM.pt\n",
        "# !wget https://github.com/voidful/BDG/releases/download/v1.0/BDG_PM.pt\n",
        "# !wget https://github.com/voidful/BDG/releases/download/v1.0/BDG.pt"
      ],
      "metadata": {
        "id": "TQqflBNzu2RR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp -r /content/BDG_PM.pt /content/gdrive/MyDrive/IR_code\n",
        "# !cp -r /content/BDG_ANPM.pt /content/gdrive/MyDrive/IR_code\n",
        "# !cp -r /content/BDG.pt /content/gdrive/MyDrive/IR_code"
      ],
      "metadata": {
        "id": "QKoP79t9vPIO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "from flask import Flask, render_template , request \n",
        "import os\n",
        "import threading\n",
        "import pickle\n",
        "from flask_bootstrap import Bootstrap\n",
        "from flask_wtf import FlaskForm\n",
        "from wtforms import StringField, SubmitField, TextAreaField\n",
        "from wtforms.validators import DataRequired\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "from pywsd.similarity import max_similarity\n",
        "import requests\n",
        "import json\n",
        "from wn import WordNet\n",
        "from pywsd.lesk import adapted_lesk\n",
        "from nltk.corpus import wordnet as wn\n",
        "nltk.download('stopwords')\n",
        "nltk.download('popular')\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from answerquest import QnAPipeline\n",
        "import nlp2go\n"
      ],
      "metadata": {
        "id": "GQuHjYKQ_W9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InputForm(FlaskForm):\n",
        "    inputText = TextAreaField('Enter Quiz Material', validators=[DataRequired()],render_kw={'rows':'10'})\n",
        "    submit = SubmitField('Generate Questions')\n"
      ],
      "metadata": {
        "id": "cMhaSqIYA0FB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_wordsense(sent,word):\n",
        "    word= word.lower()\n",
        "    \n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    \n",
        "    \n",
        "    synsets = wn.synsets(word,'n')\n",
        "    if synsets:\n",
        "        wup = max_similarity(sent, word, 'wup', pos='n')\n",
        "        adapted_lesk_output =  adapted_lesk(sent, word, pos='n')\n",
        "        lowest_index = min (synsets.index(wup),synsets.index(adapted_lesk_output))\n",
        "        return synsets[lowest_index]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def get_distractors_wordnet(syn,word):\n",
        "    distractors=[]\n",
        "    word= word.lower()\n",
        "    orig_word = word\n",
        "    if len(word.split())>0:\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    hypernym = syn.hypernyms()\n",
        "    if len(hypernym) == 0: \n",
        "        return distractors\n",
        "    for item in hypernym[0].hyponyms():\n",
        "        name = item.lemmas()[0].name()\n",
        "        #print (\"name \",name, \" word\",orig_word)\n",
        "        if name == orig_word:\n",
        "            continue\n",
        "        name = name.replace(\"_\",\" \")\n",
        "        name = \" \".join(w.capitalize() for w in name.split())\n",
        "        if name is not None and name not in distractors:\n",
        "            distractors.append(name)\n",
        "    return distractors\n",
        "\n",
        "def get_distractors_conceptnet(word):\n",
        "    word = word.lower()\n",
        "    original_word= word\n",
        "    if (len(word.split())>0):\n",
        "        word = word.replace(\" \",\"_\")\n",
        "    distractor_list = [] \n",
        "    url = \"http://api.conceptnet.io/query?node=/c/en/%s/n&rel=/r/PartOf&start=/c/en/%s&limit=5\"%(word,word)\n",
        "    obj = requests.get(url).json()\n",
        "\n",
        "    for edge in obj['edges']:\n",
        "        link = edge['end']['term'] \n",
        "\n",
        "        url2 = \"http://api.conceptnet.io/query?node=%s&rel=/r/PartOf&end=%s&limit=10\"%(link,link)\n",
        "        obj2 = requests.get(url2).json()\n",
        "        for edge in obj2['edges']:\n",
        "            word2 = edge['start']['label']\n",
        "            if word2 not in distractor_list and original_word.lower() not in word2.lower():\n",
        "                distractor_list.append(word2)\n",
        "                   \n",
        "    return distractor_list"
      ],
      "metadata": {
        "id": "RCPLMGnaw2nJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialise(qg_tokenizer_path, qg_model_path, qa_model_path ):\n",
        "  qna_pipeline = QnAPipeline(\n",
        "    qg_tokenizer_path=qg_tokenizer_path,\n",
        "    qg_model_path=qg_model_path,\n",
        "    qa_model_path=qa_model_path\n",
        "  )\n",
        "  return qna_pipeline\n",
        "qna_pipeline = initialise(\"/content/gdrive/MyDrive/IR_code/qg_augmented_model/gpt2_tokenizer_vocab/\", \"/content/gdrive/MyDrive/IR_code/qg_augmented_model/qg_augmented_model.pt\", \"/content/gdrive/MyDrive/IR_code/doc_qa_model/checkpoint-59499\")\n",
        "\n",
        "# def func(input_text):\n",
        "#     qna_pipeline, bdg_pm_model = initialise(\"/content/gdrive/MyDrive/IR_code/qg_augmented_model/gpt2_tokenizer_vocab/\", \"/content/gdrive/MyDrive/IR_code/qg_augmented_model/qg_augmented_model.pt\", \"/content/gdrive/MyDrive/IR_code/doc_qa_model/checkpoint-59499\", '/content/gdrive/MyDrive/IR_code/BDG_PM.pt')\n",
        "\n",
        "#     (sent_idxs,questions,answers) = qna_pipeline.generate_qna_items(\n",
        "#         input_text,\n",
        "#         filter_duplicate_answers=True,\n",
        "#         filter_redundant=True,\n",
        "#         sort_by_sent_order=True)\n",
        "\n",
        "#     # sent_idxs, questions, answers\n",
        "#     distractors = []\n",
        "\n",
        "#     result = []\n",
        "\n",
        "#     for a,b,c in zip(sent_idxs, questions, answers):\n",
        "#         print(a)\n",
        "\n",
        "#         strI = input_text + \" [SEP] \" + b + \" [SEP] \" + c\n",
        "#         input_json = {\n",
        "#         \"input\": strI\n",
        "#         }\n",
        "\n",
        "#         x=bdg_pm_model.predict(input_json)\n",
        "#         new_entry = dict()\n",
        "#         new_entry['question']=b\n",
        "#         new_entry['line_no']=a\n",
        "#         new_entry['ans']=c\n",
        "#         new_entry['distractor']=x['result'][0]\n",
        "#         result.append(new_entry)\n",
        "\n",
        "#     return result\n",
        "def func(qna_pipeline, input_text):\n",
        "  #qna_pipeline = initialise(\"/content/gdrive/MyDrive/IR_code/qg_augmented_model/gpt2_tokenizer_vocab/\", \"/content/gdrive/MyDrive/IR_code/qg_augmented_model/qg_augmented_model.pt\", \"/content/gdrive/MyDrive/IR_code/doc_qa_model/checkpoint-59499\")\n",
        "  (sent_idxs,questions,answers) = qna_pipeline.generate_qna_items(\n",
        "    input_text,\n",
        "    filter_duplicate_answers=True,\n",
        "    filter_redundant=True,\n",
        "    sort_by_sent_order=True)\n",
        "  \n",
        "  keyword_sentence_mapping = dict()\n",
        "\n",
        "  for i,j in zip(answers, questions):\n",
        "    keyword_sentence_mapping[i]=[j]\n",
        "\n",
        "\n",
        "  key_distractor_list = {}\n",
        "  # keyword_sentence_mapping = d\n",
        "\n",
        "  for keyword in keyword_sentence_mapping:\n",
        "    wordsense = get_wordsense(keyword_sentence_mapping[keyword][0],keyword)\n",
        "    if wordsense:\n",
        "      distractors = get_distractors_wordnet(wordsense,keyword)\n",
        "      if len(distractors) ==0:\n",
        "        distractors = get_distractors_conceptnet(keyword)\n",
        "      if len(distractors) != 0:\n",
        "        key_distractor_list[keyword] = [keyword_sentence_mapping[keyword][0]]+distractors\n",
        "    else:   \n",
        "      distractors = get_distractors_conceptnet(keyword)\n",
        "      if len(distractors) != 0:\n",
        "        key_distractor_list[keyword] = [keyword_sentence_mapping[keyword][0]]+distractors\n",
        "\n",
        "  QADlist = []\n",
        "\n",
        "  for ans, value in key_distractor_list.items():\n",
        "    d = dict()\n",
        "    d['ans'] = ans\n",
        "    d['question'] = value[0]\n",
        "    d['distractor'] = value[1:]\n",
        "\n",
        "    QADlist.append(d)\n",
        "  \n",
        "  return QADlist "
      ],
      "metadata": {
        "id": "FeUxeRHYvr16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "app = Flask(__name__,template_folder='/content/gdrive/MyDrive/IR_code/templates',static_folder='/content/gdrive/MyDrive/IR_code/static')\n",
        "ngrok.set_auth_token(\"27eM94qtit5orPFHdi2ZynwCk45_24A5V5MWUSx5o2ECzKiuh\")\n",
        "port = 5000\n",
        "public_url = ngrok.connect(port).public_url\n",
        "from google.colab.output import eval_js\n",
        "print(eval_js(\"google.colab.kernel.proxyPort(5000)\"))\n",
        "app.config[\"BASE_URL\"] = public_url\n",
        "app.config['SECRET_KEY'] = 'C2HWGVoMGfNTBsrYQg8EcMrdTimkZfAb'\n",
        "Bootstrap(app)"
      ],
      "metadata": {
        "id": "VecOr-jQveey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip --version"
      ],
      "metadata": {
        "id": "2Z15lWqSC-hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# qna_pipeline= None\n",
        "# bdg_pm_model=None\n",
        "\n",
        "# @app.before_first_request\n",
        "# def activate_job():\n",
        "#   qna_pipeline, bdg_pm_model = initialise(\"/content/gdrive/MyDrive/IR_code/qg_augmented_model/gpt2_tokenizer_vocab/\", \"/content/gdrive/MyDrive/IR_code/qg_augmented_model/qg_augmented_model.pt\", \"/content/gdrive/MyDrive/IR_code/doc_qa_model/checkpoint-59499\", '/content/gdrive/MyDrive/IR_code/BDG_PM.pt')\n",
        "\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/quizgen',methods=[\"GET\", \"POST\"])\n",
        "def quizgen():\n",
        "    \n",
        "    form = InputForm()\n",
        "    qa = []\n",
        "    if form.validate_on_submit():\n",
        "        inputData = form.inputText.data\n",
        "        qa = func(qna_pipeline, inputData)\n",
        "        print(qa)\n",
        "        #return render_template('quizgen.html',form=form,result=qa)\n",
        "    return render_template('quizgen.html',form=form,results=qa)\n",
        "print(\" * ngrok tunnel \\\"{}\\\" -> \\\"http://127.0.0.1:{}\\\"\".format(public_url, port))\n",
        "app.run()\n"
      ],
      "metadata": {
        "id": "dtdLgtTz_duh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}